#!/usr/bin/env python3
"""
åˆå¹¶å¤šä¸ªæ¨¡å‹çš„è¯„æµ‹ç»“æœï¼Œç”Ÿæˆå®Œæ•´çš„è®ºæ–‡é£æ ¼è¡¨æ ¼

å‚è€ƒREOBenchè®ºæ–‡è¡¨æ ¼æ ¼å¼:
- Table 1: Scene classification
- Table 2: Semantic segmentation
- Table 3: Object detection
- Table 4: Image captioning
- Table 5: VQA
- Table 6: Visual grounding

ä½¿ç”¨æ–¹æ³•:
    python merge_results_to_table.py --input_dir ./outputs --task vqa --output paper_table.xlsx

    æˆ–è€…æŒ‡å®šå¤šä¸ªJSONæ–‡ä»¶:
    python merge_results_to_table.py --files results1.json results2.json --output paper_table.xlsx
"""

import os
import json
import argparse
import numpy as np
import pandas as pd
from pathlib import Path
from datetime import datetime


def load_results(json_file):
    """åŠ è½½å•ä¸ªç»“æœæ–‡ä»¶"""
    with open(json_file, 'r') as f:
        return json.load(f)


def extract_metrics_from_stats(stats, task_name):
    """ä»ç»Ÿè®¡ä¿¡æ¯ä¸­æå–æŒ‡æ ‡"""
    if task_name == 'grounding':
        metric_key = 'accuracy@0.5'
        is_percentage = True
    elif task_name == 'vqa':
        metric_key = 'accuracy'
        is_percentage = True
    elif task_name == 'caption':
        metric_key = 'mean_score'
        is_percentage = False
    else:
        metric_key = 'accuracy'
        is_percentage = True

    return metric_key, is_percentage


def process_single_result(result_data):
    """å¤„ç†å•ä¸ªç»“æœæ–‡ä»¶ï¼Œæå–å…³é”®æŒ‡æ ‡"""
    config = result_data.get('config', {})
    stats = result_data.get('statistics', {})

    model_type = config.get('model_type', 'unknown')
    dataset = config.get('dataset', 'unknown')
    task = config.get('task', 'unknown')

    metric_key, is_percentage = extract_metrics_from_stats(stats, task)

    # æå–å„æ‰°åŠ¨ç±»å‹çš„æ•°æ®
    perturbation_data = {}
    clean_metric = None
    overall_metric = None

    for key, s in stats.items():
        if key == 'all_perturbations_overall':
            overall_metric = s.get(metric_key, s.get('mean_score', s.get('mean_iou', 0)))
            continue

        if key == 'none_s0':
            clean_metric = s.get(metric_key, s.get('mean_score', s.get('mean_iou', 0)))
        else:
            # è·³è¿‡éæ‰°åŠ¨ç»Ÿè®¡é”®
            if key in ['caption_standard_metrics'] or not key.endswith(tuple(f'_s{i}' for i in range(10))):
            	continue
            # è§£ææ‰°åŠ¨ç±»å‹å’Œä¸¥é‡ç¨‹åº¦
            parts = key.split('_s')
            if len(parts) == 2:
                perturb_type = parts[0]
                severity = int(parts[1])

                if perturb_type not in perturbation_data:
                    perturbation_data[perturb_type] = {}

                perturbation_data[perturb_type][severity] = s.get(metric_key, s.get('mean_score', s.get('mean_iou', 0)))

    # è®¡ç®—æ¯ç§æ‰°åŠ¨ç±»å‹çš„å¹³å‡å€¼
    perturb_avg = {}
    for perturb_type, severity_data in perturbation_data.items():
        if severity_data:
            perturb_avg[perturb_type] = np.mean(list(severity_data.values()))

    return {
        'model_type': model_type,
        'dataset': dataset,
        'task': task,
        'clean': clean_metric,
        'overall_avg': overall_metric,
        'perturbation_avg': perturb_avg,
        'perturbation_detail': perturbation_data,
        'is_percentage': is_percentage
    }


def merge_same_setting(results_list):
    """\
    å°†åŒä¸€ä¸ª (model_type, dataset, task) çš„å¤šä»½ç»“æœåˆå¹¶æˆä¸€æ¡å®Œæ•´è®°å½•ã€‚

    è¯´æ˜ï¼š
    - ä½ çš„ pipeline å¯èƒ½ä¼šå¯¹åŒä¸€ç»„é…ç½®åˆ†åˆ«è·‘ clean å’Œ perturbed ä¸¤æ¬¡è¯„æµ‹ï¼Œ
      å¯¼è‡´ç”Ÿæˆä¸¤ä»½ results_*.jsonï¼ˆåˆ†åˆ«åªæœ‰ Clean æˆ–åªæœ‰æ‰°åŠ¨åˆ—ï¼‰ã€‚
    - è¯¥å‡½æ•°ä¼šæŠŠå®ƒä»¬åˆå¹¶ï¼Œé¿å…æœ€ç»ˆ CSV/Excel ä¸­å¤§é‡ '-' çš„å ä½ã€‚

    åˆå¹¶ç­–ç•¥ï¼ˆå°½é‡ä¿æŒåŸæœ‰æ ¸å¿ƒåŠŸèƒ½ä¸å˜ï¼‰ï¼š
    - clean / overall_avgï¼šå–é None çš„å€¼ï¼ˆä¼˜å…ˆå·²å­˜åœ¨çš„ï¼‰
    - perturbation_detailï¼šæŒ‰æ‰°åŠ¨ç±»å‹ã€å¼ºåº¦åšå­—å…¸æ·±åˆå¹¶
    - perturbation_avgï¼šåŸºäºåˆå¹¶åçš„ detail é‡æ–°è®¡ç®—å‡å€¼
    - is_percentageï¼šå¿…é¡»ä¸€è‡´ï¼Œå¦åˆ™æŠ¥é”™ï¼ˆé¿å…ä¸åŒä»»åŠ¡æŒ‡æ ‡æ··æ·†ï¼‰
    """
    if not results_list:
        return results_list

    merged = {}

    for r in results_list:
        key = (r.get('model_type'), r.get('dataset'), r.get('task'))

        if key not in merged:
            merged[key] = {
                'model_type': r.get('model_type'),
                'dataset': r.get('dataset'),
                'task': r.get('task'),
                'clean': None,
                'overall_avg': None,
                'perturbation_avg': {},
                'perturbation_detail': {},
                'is_percentage': r.get('is_percentage', True),
            }

        m = merged[key]

        # æŒ‡æ ‡ç±»å‹å¿…é¡»ä¸€è‡´
        if m.get('is_percentage') != r.get('is_percentage', True):
            raise ValueError(
                f"is_percentage mismatch for {key}: {m.get('is_percentage')} vs {r.get('is_percentage')}"
            )

        # clean / overall å–é None
        if m.get('clean') is None and r.get('clean') is not None:
            m['clean'] = r.get('clean')

        if m.get('overall_avg') is None and r.get('overall_avg') is not None:
            m['overall_avg'] = r.get('overall_avg')

        # æ·±åˆå¹¶æ‰°åŠ¨æ˜ç»†
        detail = r.get('perturbation_detail') or {}
        for pt, sev_map in detail.items():
            if pt not in m['perturbation_detail']:
                m['perturbation_detail'][pt] = {}
            if isinstance(sev_map, dict):
                m['perturbation_detail'][pt].update(sev_map)

    # åŸºäº detail é‡ç®— perturbation_avg
    for m in merged.values():
        pert_avg = {}
        for pt, sev_map in (m.get('perturbation_detail') or {}).items():
            if isinstance(sev_map, dict) and len(sev_map) > 0:
                pert_avg[pt] = float(np.mean(list(sev_map.values())))
        m['perturbation_avg'] = pert_avg

    return list(merged.values())


def format_value(val, is_pct=True, decimals=2):
    """æ ¼å¼åŒ–æ•°å€¼"""
    if val is None:
        return '-'
    if is_pct:
        return round(val * 100, decimals)
    return round(val, decimals + 2)


def generate_merged_table(results_list, output_excel, output_csv=None):
    """
    åˆå¹¶å¤šä¸ªæ¨¡å‹ç»“æœï¼Œç”Ÿæˆè®ºæ–‡æ ¼å¼è¡¨æ ¼

    Args:
        results_list: å¤„ç†åçš„ç»“æœåˆ—è¡¨
        output_excel: è¾“å‡ºExcelæ–‡ä»¶è·¯å¾„
        output_csv: è¾“å‡ºCSVæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
    """
    if not results_list:
        print("âŒ æ²¡æœ‰ç»“æœå¯ä»¥åˆå¹¶")
        return

    # è·å–æ‰€æœ‰æ‰°åŠ¨ç±»å‹
    all_perturb_types = set()
    for r in results_list:
        all_perturb_types.update(r['perturbation_avg'].keys())

    all_perturb_types = sorted(list(all_perturb_types))

    # æ„å»ºè¡¨æ ¼æ•°æ®
    table_data = []

    for r in results_list:
        row = {
            'Model': r['model_type'],
            'Dataset': r['dataset'],
            'Task': r['task'],
            'Clean': format_value(r['clean'], r['is_percentage']),
        }

        # æ·»åŠ å„æ‰°åŠ¨ç±»å‹çš„å¹³å‡å€¼åˆ—
        for perturb_type in all_perturb_types:
            val = r['perturbation_avg'].get(perturb_type)
            row[perturb_type] = format_value(val, r['is_percentage'])

        # æ·»åŠ overall average
        row['Avg'] = format_value(r['overall_avg'], r['is_percentage'])

        # è®¡ç®—delta (clean - avg)
        if r['clean'] is not None and r['overall_avg'] is not None:
            delta = r['clean'] - r['overall_avg']
            row['Î”TP'] = format_value(delta, r['is_percentage'])
        else:
            row['Î”TP'] = '-'

        table_data.append(row)

    # è½¬ä¸ºDataFrame
    df = pd.DataFrame(table_data)

    # æ’åº
    df = df.sort_values(['Task', 'Dataset', 'Model'])

    # ä¿å­˜Excel
    with pd.ExcelWriter(output_excel, engine='openpyxl') as writer:
        df.to_excel(writer, sheet_name='Results', index=False)

    print(f"âœ… å·²ä¿å­˜Excelè¡¨æ ¼: {output_excel}")

    # ä¿å­˜CSVï¼ˆå¯é€‰ï¼‰
    if output_csv:
        df.to_csv(output_csv, index=False)
        print(f"âœ… å·²ä¿å­˜CSVè¡¨æ ¼: {output_csv}")


def find_result_files(input_dir, task_filter=None, dataset_filter=None):
    """åœ¨ç›®å½•ä¸­æŸ¥æ‰¾ç»“æœæ–‡ä»¶"""
    input_dir = Path(input_dir)
    if not input_dir.exists():
        return []

    result_files = list(input_dir.rglob("results_*.json"))

    # è¿‡æ»¤ä»»åŠ¡å’Œæ•°æ®é›†
    filtered_files = []
    for f in result_files:
        try:
            data = load_results(f)
            config = data.get('config', {})

            if task_filter and config.get('task') != task_filter:
                continue

            if dataset_filter and config.get('dataset') != dataset_filter:
                continue

            filtered_files.append(str(f))
        except:
            continue

    return filtered_files


def main():
    parser = argparse.ArgumentParser(description="åˆå¹¶å¤šä¸ªæ¨¡å‹è¯„æµ‹ç»“æœç”Ÿæˆè¡¨æ ¼")
    parser.add_argument("--input_dir", type=str, default=None,
                        help="åŒ…å«ç»“æœJSONæ–‡ä»¶çš„ç›®å½•")
    parser.add_argument("--files", nargs='+', type=str, default=None,
                        help="ç›´æ¥æŒ‡å®šç»“æœJSONæ–‡ä»¶åˆ—è¡¨")
    parser.add_argument("--task", type=str, default=None,
                        choices=['vqa', 'caption', 'grounding'],
                        help="è¿‡æ»¤ç‰¹å®šä»»åŠ¡")
    parser.add_argument("--dataset", type=str, default=None,
                        help="è¿‡æ»¤ç‰¹å®šæ•°æ®é›†")
    parser.add_argument("--output", type=str, default=None,
                        help="è¾“å‡ºExcelæ–‡ä»¶å")
    parser.add_argument("--output_csv", type=str, default=None,
                        help="è¾“å‡ºCSVæ–‡ä»¶å")

    args = parser.parse_args()

    # æ”¶é›†ç»“æœæ–‡ä»¶
    result_files = []

    if args.files:
        result_files = args.files
    elif args.input_dir:
        result_files = find_result_files(args.input_dir, args.task, args.dataset)
    else:
        print("âŒ è¯·æŒ‡å®š --input_dir æˆ– --files")
        return

    if not result_files:
        print("âŒ æœªæ‰¾åˆ°ä»»ä½•ç»“æœæ–‡ä»¶")
        return

    print(f"ğŸ“‚ æ‰¾åˆ° {len(result_files)} ä¸ªç»“æœæ–‡ä»¶:")
    for f in result_files:
        print(f"   - {f}")

    # åŠ è½½å¹¶å¤„ç†ç»“æœ
    results_list = []
    for filepath in result_files:
        try:
            data = load_results(filepath)
            processed = process_single_result(data)
            results_list.append(processed)
            print(f"   âœ“ å·²åŠ è½½: {processed['model_type']} / {processed['dataset']} / {processed['task']}")
        except Exception as e:
            print(f"   âš ï¸ åŠ è½½å¤±è´¥ {filepath}: {e}")

    if not results_list:
        print("âŒ æ²¡æœ‰æœ‰æ•ˆçš„ç»“æœ")
        return

    # åˆå¹¶åŒä¸€ç»„ (model/dataset/task) çš„å¤šä»½ç»“æœï¼ˆä¾‹å¦‚ clean-run ä¸ perturbed-runï¼‰
    results_list = merge_same_setting(results_list)

    # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

    if args.output:
        output_excel = args.output
    else:
        task_str = args.task or 'all'
        output_excel = f"paper_table_{task_str}_{timestamp}.xlsx"

    output_csv = args.output_csv or output_excel.replace('.xlsx', '.csv')

    # ç”Ÿæˆè¡¨æ ¼
    generate_merged_table(results_list, output_excel, output_csv)


if __name__ == "__main__":
    main()

# #!/usr/bin/env python3
# """
# åˆå¹¶å¤šä¸ªæ¨¡å‹çš„è¯„æµ‹ç»“æœï¼Œç”Ÿæˆå®Œæ•´çš„è®ºæ–‡é£æ ¼è¡¨æ ¼

# å‚è€ƒREOBenchè®ºæ–‡è¡¨æ ¼æ ¼å¼:
# - Table 1: Scene classification
# - Table 2: Semantic segmentation  
# - Table 3: Object detection
# - Table 4: Image captioning
# - Table 5: VQA
# - Table 6: Visual grounding

# ä½¿ç”¨æ–¹æ³•:
#     python merge_results_to_table.py --input_dir ./outputs --task vqa --output paper_table.xlsx
    
#     æˆ–è€…æŒ‡å®šå¤šä¸ªJSONæ–‡ä»¶:
#     python merge_results_to_table.py --files results1.json results2.json --output paper_table.xlsx
# """

# import os
# import json
# import argparse
# import numpy as np
# import pandas as pd
# from pathlib import Path
# from datetime import datetime


# def load_results(json_file):
#     """åŠ è½½å•ä¸ªç»“æœæ–‡ä»¶"""
#     with open(json_file, 'r') as f:
#         return json.load(f)


# def extract_metrics_from_stats(stats, task_name):
#     """ä»ç»Ÿè®¡ä¿¡æ¯ä¸­æå–æŒ‡æ ‡"""
#     if task_name == 'grounding':
#         metric_key = 'accuracy@0.5'
#         is_percentage = True
#     elif task_name == 'vqa':
#         metric_key = 'accuracy'
#         is_percentage = True
#     elif task_name == 'caption':
#         metric_key = 'mean_score'
#         is_percentage = False
#     else:
#         metric_key = 'accuracy'
#         is_percentage = True
    
#     return metric_key, is_percentage


# def process_single_result(result_data):
#     """å¤„ç†å•ä¸ªç»“æœæ–‡ä»¶ï¼Œæå–å…³é”®æŒ‡æ ‡"""
#     config = result_data.get('config', {})
#     stats = result_data.get('statistics', {})
    
#     model_type = config.get('model_type', 'unknown')
#     dataset = config.get('dataset', 'unknown')
#     task = config.get('task', 'unknown')
    
#     metric_key, is_percentage = extract_metrics_from_stats(stats, task)
    
#     # æå–å„æ‰°åŠ¨ç±»å‹çš„æ•°æ®
#     perturbation_data = {}
#     clean_metric = None
#     overall_metric = None
    
#     for key, s in stats.items():
#         if key == 'all_perturbations_overall':
#             overall_metric = s.get(metric_key, s.get('mean_score', s.get('mean_iou', 0)))
#             continue
        
#         if key == 'none_s0':
#             clean_metric = s.get(metric_key, s.get('mean_score', s.get('mean_iou', 0)))
#         else:
#             parts = key.rsplit('_s', 1)
#             if len(parts) == 2:
#                 pert_type = parts[0]
#                 severity = int(parts[1])
                
#                 if pert_type not in perturbation_data:
#                     perturbation_data[pert_type] = {}
                
#                 metric_value = s.get(metric_key, s.get('mean_score', s.get('mean_iou', 0)))
#                 perturbation_data[pert_type][severity] = metric_value
    
#     # è®¡ç®—æ¯ç§æ‰°åŠ¨çš„å¹³å‡å€¼
#     pert_avg = {}
#     for pert_type, severities in perturbation_data.items():
#         pert_avg[pert_type] = np.mean(list(severities.values()))
    
#     return {
#         'model_type': model_type,
#         'dataset': dataset,
#         'task': task,
#         'clean': clean_metric,
#         'overall_avg': overall_metric,
#         'perturbation_avg': pert_avg,
#         'perturbation_detail': perturbation_data,
#         'is_percentage': is_percentage
#     }


# def format_value(val, is_pct=True, decimals=2):
#     """æ ¼å¼åŒ–æ•°å€¼"""
#     if val is None:
#         return '-'
#     if is_pct:
#         return round(val * 100, decimals)
#     return round(val, decimals + 2)


# def generate_merged_table(results_list, output_excel, output_csv=None):
#     """
#     åˆå¹¶å¤šä¸ªæ¨¡å‹ç»“æœï¼Œç”Ÿæˆè®ºæ–‡æ ¼å¼è¡¨æ ¼
    
#     Args:
#         results_list: å¤„ç†åçš„ç»“æœåˆ—è¡¨
#         output_excel: è¾“å‡ºExcelæ–‡ä»¶è·¯å¾„
#         output_csv: è¾“å‡ºCSVæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
#     """
#     if not results_list:
#         print("âŒ æ²¡æœ‰ç»“æœå¯ä»¥åˆå¹¶")
#         return
    
#     # æ”¶é›†æ‰€æœ‰æ‰°åŠ¨ç±»å‹
#     all_perturbations = set()
#     for r in results_list:
#         all_perturbations.update(r['perturbation_avg'].keys())
    
#     # å®šä¹‰æ ‡å‡†åˆ—é¡ºåº (å‚è€ƒREOBench)
#     standard_order = [
#         'brightness', 'cloud', 'compression', 'gap', 'gaussian_blur', 
#         'gaussian_noise', 'haze', 'motion_blur', 'salt_pepper', 
#         'rotate', 'scale', 'translate'
#     ]
    
#     sorted_perts = []
#     for p in standard_order:
#         if p in all_perturbations:
#             sorted_perts.append(p)
#     for p in sorted(all_perturbations):
#         if p not in sorted_perts:
#             sorted_perts.append(p)
    
#     # ============================================
#     # ç”Ÿæˆä¸»è¡¨æ ¼ (REOBenché£æ ¼)
#     # ============================================
#     rows = []
#     for r in results_list:
#         is_pct = r['is_percentage']
        
#         row = {
#             'Model': r['model_type'],
#             'Backbone': 'ViT-L',  # å¯æ ¹æ®å®é™…ä¿®æ”¹
#             'Clean': format_value(r['clean'], is_pct)
#         }
        
#         for pert_type in sorted_perts:
#             col_name = pert_type.replace('_', ' ').title()
#             if pert_type in r['perturbation_avg']:
#                 row[col_name] = format_value(r['perturbation_avg'][pert_type], is_pct)
#             else:
#                 row[col_name] = '-'
        
#         row['Avg'] = format_value(r['overall_avg'], is_pct)
        
#         if r['clean'] is not None and r['overall_avg'] is not None:
#             delta_tp = r['clean'] - r['overall_avg']
#             row['Î”TP'] = format_value(delta_tp, is_pct)
#         else:
#             row['Î”TP'] = '-'
        
#         rows.append(row)
    
#     df_main = pd.DataFrame(rows)
    
#     # ============================================
#     # ç”Ÿæˆè¯¦ç»†è¡¨æ ¼ (æ¯ä¸ªæ¨¡å‹æ¯ä¸ªæ‰°åŠ¨æ¯ä¸ªseverity)
#     # ============================================
#     detail_rows = []
#     for r in results_list:
#         is_pct = r['is_percentage']
        
#         # Clean
#         detail_rows.append({
#             'Model': r['model_type'],
#             'Perturbation': 'Clean',
#             'Severity': '-',
#             'Value': format_value(r['clean'], is_pct)
#         })
        
#         # å„æ‰°åŠ¨
#         for pert_type in sorted_perts:
#             if pert_type in r['perturbation_detail']:
#                 for sev, val in sorted(r['perturbation_detail'][pert_type].items()):
#                     detail_rows.append({
#                         'Model': r['model_type'],
#                         'Perturbation': pert_type.replace('_', ' ').title(),
#                         'Severity': sev,
#                         'Value': format_value(val, is_pct)
#                     })
        
#         # Overall
#         detail_rows.append({
#             'Model': r['model_type'],
#             'Perturbation': 'All Perturbations Avg',
#             'Severity': '-',
#             'Value': format_value(r['overall_avg'], is_pct)
#         })
    
#     df_detail = pd.DataFrame(detail_rows)
    
#     # ============================================
#     # ç”ŸæˆLaTeXè¡¨æ ¼ä»£ç 
#     # ============================================
#     latex_header = ['Model', 'Backbone', 'Clean'] + \
#                    [p.replace('_', ' ').title() for p in sorted_perts] + \
#                    ['Avg', 'Î”TP']
    
#     latex_lines = []
#     latex_lines.append('% LaTeX Table Code (copy to your paper)')
#     latex_lines.append('\\begin{table}[h]')
#     latex_lines.append('\\centering')
#     latex_lines.append('\\caption{Performance under different image perturbations}')
#     latex_lines.append('\\resizebox{\\textwidth}{!}{')
#     latex_lines.append('\\begin{tabular}{' + 'l' * len(latex_header) + '}')
#     latex_lines.append('\\toprule')
#     latex_lines.append(' & '.join(latex_header) + ' \\\\')
#     latex_lines.append('\\midrule')
    
#     for _, row in df_main.iterrows():
#         values = [str(row.get(col, '-')) for col in latex_header]
#         latex_lines.append(' & '.join(values) + ' \\\\')
    
#     latex_lines.append('\\bottomrule')
#     latex_lines.append('\\end{tabular}}')
#     latex_lines.append('\\end{table}')
    
#     latex_code = '\n'.join(latex_lines)
    
#     # ============================================
#     # ä¿å­˜æ–‡ä»¶
#     # ============================================
#     try:
#         with pd.ExcelWriter(output_excel, engine='openpyxl') as writer:
#             df_main.to_excel(writer, sheet_name='Main_Table', index=False)
#             df_detail.to_excel(writer, sheet_name='Detailed', index=False)
            
#             # LaTeXä»£ç 
#             df_latex = pd.DataFrame({'LaTeX_Code': [latex_code]})
#             df_latex.to_excel(writer, sheet_name='LaTeX', index=False)
        
#         print(f"âœ… Excelè¡¨æ ¼å·²ä¿å­˜: {output_excel}")
#     except Exception as e:
#         print(f"âŒ Excelä¿å­˜å¤±è´¥: {e}")
    
#     if output_csv:
#         try:
#             df_main.to_csv(output_csv, index=False)
#             print(f"âœ… CSVè¡¨æ ¼å·²ä¿å­˜: {output_csv}")
#         except Exception as e:
#             print(f"âŒ CSVä¿å­˜å¤±è´¥: {e}")
    
#     # æ‰“å°é¢„è§ˆ
#     print(f"\n{'='*80}")
#     print("ğŸ“‹ è®ºæ–‡è¡¨æ ¼é¢„è§ˆ (REOBenché£æ ¼)")
#     print(f"{'='*80}")
#     print(df_main.to_string(index=False))
#     print(f"\n{'='*80}")
#     print("ğŸ“‹ LaTeXä»£ç é¢„è§ˆ")
#     print(f"{'='*80}")
#     print(latex_code)
    
#     return df_main, df_detail


# def find_result_files(input_dir, task=None, dataset=None):
#     """åœ¨ç›®å½•ä¸­æŸ¥æ‰¾ç»“æœæ–‡ä»¶"""
#     result_files = []
    
#     for root, dirs, files in os.walk(input_dir):
#         for f in files:
#             if f.startswith('results_') and f.endswith('.json'):
#                 filepath = os.path.join(root, f)
                
#                 # è¿‡æ»¤
#                 if task or dataset:
#                     try:
#                         with open(filepath, 'r') as fp:
#                             data = json.load(fp)
#                             config = data.get('config', {})
                            
#                             if task and config.get('task') != task:
#                                 continue
#                             if dataset and config.get('dataset') != dataset:
#                                 continue
#                     except:
#                         continue
                
#                 result_files.append(filepath)
    
#     return result_files


# def main():
#     parser = argparse.ArgumentParser(description="åˆå¹¶å¤šä¸ªæ¨¡å‹ç»“æœç”Ÿæˆè®ºæ–‡è¡¨æ ¼")
    
#     parser.add_argument("--input_dir", type=str, default=None,
#                         help="åŒ…å«ç»“æœæ–‡ä»¶çš„ç›®å½•")
#     parser.add_argument("--files", nargs='+', type=str, default=None,
#                         help="ç›´æ¥æŒ‡å®šç»“æœJSONæ–‡ä»¶åˆ—è¡¨")
#     parser.add_argument("--task", type=str, default=None,
#                         choices=['vqa', 'caption', 'grounding'],
#                         help="è¿‡æ»¤ç‰¹å®šä»»åŠ¡")
#     parser.add_argument("--dataset", type=str, default=None,
#                         help="è¿‡æ»¤ç‰¹å®šæ•°æ®é›†")
#     parser.add_argument("--output", type=str, default=None,
#                         help="è¾“å‡ºExcelæ–‡ä»¶å")
#     parser.add_argument("--output_csv", type=str, default=None,
#                         help="è¾“å‡ºCSVæ–‡ä»¶å")
    
#     args = parser.parse_args()
    
#     # æ”¶é›†ç»“æœæ–‡ä»¶
#     result_files = []
    
#     if args.files:
#         result_files = args.files
#     elif args.input_dir:
#         result_files = find_result_files(args.input_dir, args.task, args.dataset)
#     else:
#         print("âŒ è¯·æŒ‡å®š --input_dir æˆ– --files")
#         return
    
#     if not result_files:
#         print("âŒ æœªæ‰¾åˆ°ä»»ä½•ç»“æœæ–‡ä»¶")
#         return
    
#     print(f"ğŸ“‚ æ‰¾åˆ° {len(result_files)} ä¸ªç»“æœæ–‡ä»¶:")
#     for f in result_files:
#         print(f"   - {f}")
    
#     # åŠ è½½å¹¶å¤„ç†ç»“æœ
#     results_list = []
#     for filepath in result_files:
#         try:
#             data = load_results(filepath)
#             processed = process_single_result(data)
#             results_list.append(processed)
#             print(f"   âœ“ å·²åŠ è½½: {processed['model_type']} / {processed['dataset']} / {processed['task']}")
#         except Exception as e:
#             print(f"   âš ï¸ åŠ è½½å¤±è´¥ {filepath}: {e}")
    
#     if not results_list:
#         print("âŒ æ²¡æœ‰æœ‰æ•ˆçš„ç»“æœ")
#         return
    
#     # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
#     timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
#     if args.output:
#         output_excel = args.output
#     else:
#         task_str = args.task or 'all'
#         output_excel = f"paper_table_{task_str}_{timestamp}.xlsx"
    
#     output_csv = args.output_csv or output_excel.replace('.xlsx', '.csv')
    
#     # ç”Ÿæˆè¡¨æ ¼
#     generate_merged_table(results_list, output_excel, output_csv)


# if __name__ == "__main__":
#     main()
