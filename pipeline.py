#!/usr/bin/env python3
# pipeline.py - ä¿®å¤ç‰ˆé€šç”¨åˆ†å‰²æ¨¡å‹å¯¹æŠ—æ”»å‡»ä¸è¯„ä¼°ç®¡é“
import os
import json
import time
import argparse
import torch
import numpy as np
import cv2
import pandas as pd
import matplotlib.pyplot as plt
from datetime import datetime
from typing import Tuple, Dict, Any, Optional, List
from pathlib import Path

from model_zoo import create_model, list_available_models

class share_var:
    debug_custom_number = 30

local_share_var = share_var()

def scale_bbox_to_256(bbox: list, original_size: tuple) -> list:
    """å°†è¾¹ç•Œæ¡†ç¼©æ”¾åˆ°256Ã—256ï¼ˆçº¯ç²¹çš„æ•°å­¦è®¡ç®—ï¼Œä¸åˆ¤æ–­æ¨¡å‹ç±»å‹ï¼‰"""
    if bbox is None:
        return None
    
    orig_h, orig_w = original_size
    scale_h = 256 / orig_h
    scale_w = 256 / orig_w
    
    scaled_bbox = [
        bbox[0] * scale_w,  # x1
        bbox[1] * scale_h,  # y1  
        bbox[2] * scale_w,  # x2
        bbox[3] * scale_h   # y2
    ]
    
    print(f"ğŸ“¦ [è¾¹ç•Œæ¡†ç¼©æ”¾] {bbox} â†’ {[round(x, 1) for x in scaled_bbox]}")
    
    return scaled_bbox

def validate_image_mask_correspondence(img_path, mask_path, base_name):
    """
    ä¸¥æ ¼éªŒè¯å›¾åƒå’Œæ©ç çš„å°ºå¯¸å¯¹åº”å…³ç³»
    å¦‚æœä¸åŒ¹é…ï¼Œç›´æ¥æŠ›å‡ºå¼‚å¸¸
    """
    import cv2
    import os
    
    # è¯»å–å›¾åƒå’Œæ©ç çš„åŸå§‹å°ºå¯¸
    img = cv2.imread(img_path)
    mask = cv2.imread(mask_path, 0)
    
    if img is None:
        raise FileNotFoundError(f"âŒ æ— æ³•è¯»å–å›¾åƒæ–‡ä»¶: {img_path}")
    if mask is None:
        raise FileNotFoundError(f"âŒ æ— æ³•è¯»å–æ©ç æ–‡ä»¶: {mask_path}")
    
    img_size = img.shape[:2]  # (H, W)
    mask_size = mask.shape    # (H, W)
    
    print(f"ğŸ” [éªŒè¯] {base_name}: å›¾åƒ{img_size} vs æ©ç {mask_size}")
    
    # ä¸¥æ ¼æ£€æŸ¥å°ºå¯¸åŒ¹é…
    if img_size != mask_size:
        error_msg = f"""
        âŒ æ•°æ®ä¸ä¸€è‡´é”™è¯¯ï¼
           å›¾åƒ: {os.path.basename(img_path)} - å°ºå¯¸: {img_size}
           æ©ç : {os.path.basename(mask_path)} - å°ºå¯¸: {mask_size}
           
        ğŸš¨ æ‰°åŠ¨å›¾åƒå’ŒçœŸå®æ©ç çš„å°ºå¯¸ä¸åŒ¹é…ï¼
           è¿™è¡¨æ˜å®ƒä»¬æ¥è‡ªä¸åŒçš„æ•°æ®æºï¼Œä¼šå¯¼è‡´é”™è¯¯çš„è¯„ä¼°ç»“æœã€‚
           
        ğŸ”§ å»ºè®®è§£å†³æ–¹æ¡ˆ:
           1. æ£€æŸ¥æ‰°åŠ¨æ•°æ®é›†çš„ç”Ÿæˆè¿‡ç¨‹
           2. ç¡®ä¿æ‰°åŠ¨å›¾åƒå’Œæ©ç æ¥è‡ªåŒä¸€åŸå§‹æ•°æ®é›†
           3. é‡æ–°ç”ŸæˆåŒ¹é…å°ºå¯¸çš„æ‰°åŠ¨æ•°æ®é›†
           
        ç¨‹åºå·²åœæ­¢ä»¥é¿å…äº§ç”Ÿé”™è¯¯ç»“æœã€‚
        """
        raise ValueError(error_msg)
    
    print(f"âœ… [éªŒè¯] å°ºå¯¸åŒ¹é…")
    return img_size

# -------------------- å‚æ•°è§£æ --------------------
def get_parser():
    parser = argparse.ArgumentParser(description="é€šç”¨åˆ†å‰²æ¨¡å‹å¯¹æŠ—æ”»å‡»ä¸è¯„ä¼°")
    parser.add_argument("--model_config", default="model_config.json", help="æ¨¡å‹é…ç½®æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--dataset_config", default="dataset_config.json", help="æ•°æ®é›†é…ç½®æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--model_name", default="medsam", help=f"è¦ä½¿ç”¨çš„æ¨¡å‹ï¼Œæ”¯æŒ: {list_available_models()}")
    # parser.add_argument("--dataset_name", default="isic_2016", help="è¦ä½¿ç”¨çš„æ•°æ®é›†åç§°")
    parser.add_argument("--dataset_name", nargs='+', default=["isic_2016"], help="è¦ä½¿ç”¨çš„æ•°æ®é›†åç§°ï¼›both æ¨¡å¼ä¸‹éœ€ä¼  2 ä¸ªï¼ˆåŸå§‹ æ‰°åŠ¨ï¼‰")
    parser.add_argument("--attack_types", nargs="+", default=["fgsm", "pgd"], help="å¯¹æŠ—æ”»å‡»ç±»å‹")
    parser.add_argument("--levels", nargs="+", type=int, default=[1, 2, 3, 4, 5], help="æ‰°åŠ¨çº§åˆ«")
    parser.add_argument("--targeted", action="store_true", help="æ˜¯å¦ä¸ºç›®æ ‡å¯¹æŠ—æ‰°åŠ¨")
    parser.add_argument("--eval_mode", choices=["adversarial", "perturbation", "both"], default="adversarial", help="è¯„ä¼°æ¨¡å¼")
    parser.add_argument("--output_root", default=None, help="è¾“å‡ºæ ¹ç›®å½•ï¼Œä¸ºç©ºåˆ™ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„è®¾ç½®")
    parser.add_argument("--device", default="cuda" if torch.cuda.is_available() else "cpu", help="è®¡ç®—è®¾å¤‡")
    parser.add_argument("--debug", action="store_true", help="å¯ç”¨è°ƒè¯•æ¨¡å¼")
    parser.add_argument("--save_visualizations", action="store_true", default=True, help="ä¿å­˜å¯è§†åŒ–ç»“æœï¼ˆé»˜è®¤å¯ç”¨ï¼‰")
    parser.add_argument("--no_visualizations", action="store_true", help="ç¦ç”¨å¯è§†åŒ–ä¿å­˜")
    parser.add_argument("--max_images", type=int, default=None, help="é™åˆ¶å¤„ç†çš„å›¾åƒæ•°é‡ï¼ˆç”¨äºæµ‹è¯•ï¼Œé»˜è®¤å¤„ç†å…¨éƒ¨ï¼‰")
    parser.add_argument("--perturbation_path", default="/mnt/fast/nobackup/scratch4weeks/ly0008/cxx/data/perturbed_datasets", help="æ‰°åŠ¨æ•°æ®é›†è·¯å¾„ï¼ˆç”¨äºperturbationæ¨¡å¼ï¼‰")
    parser.add_argument("--finetune_checkpoint", type=str, default=None, help="å¾®è°ƒæ¨¡å‹æ£€æŸ¥ç‚¹è·¯å¾„ï¼ˆå¯é€‰ï¼Œä¸æä¾›åˆ™ä½¿ç”¨åŸå§‹é¢„è®­ç»ƒæ¨¡å‹ï¼‰")
    parser.add_argument("--data_split_json", type=str, default=None, help="æ•°æ®åˆ’åˆ†æ–‡ä»¶è·¯å¾„ï¼ˆfinetune.pyç”Ÿæˆçš„data_split.jsonï¼‰ï¼Œç”¨äºåªè¯„ä¼°æµ‹è¯•é›†")
    return parser

# -------------------- é…ç½®åŠ è½½å™¨ --------------------
class ConfigLoader:
    def __init__(self, model_config_path: str, dataset_config_path: str):
        self.model_config = self._load_json_with_fallback(model_config_path, self._get_default_model_config())
        self.dataset_config = self._load_json_with_fallback(dataset_config_path, self._get_default_dataset_config())

    def _load_json_with_fallback(self, path: str, fallback_config: Dict[str, Any]) -> Dict[str, Any]:
        try:
            if os.path.exists(path):
                with open(path, 'r', encoding='utf-8') as f:
                    return json.load(f)
        except Exception:
            pass
        return fallback_config

    def _get_default_model_config(self) -> Dict[str, Any]:
        return {
            "medsam": {
                "name": "medsam",
                "repo_id": "flaviagiammarino/medsam-vit-base",
                "local_path": None,
                "prompt_type": "box",
                "prompt_required": True,
                "image_size": 1024,
                "normalize_mean": [0.485, 0.456, 0.406],
                "normalize_std": [0.229, 0.224, 0.225],
                "notes": "åŒ»å­¦ä¸“ç”¨ SAMï¼Œéœ€è¦ box æç¤º"
            }
        }

    def _get_default_dataset_config(self) -> Dict[str, Any]:
        return {
            "datasets": {
                "isic_2016": {
                    "name": "ISIC 2016",
                    "resized_img_dir": "./data/images",
                    "resized_mask_dir": "./data/masks",
                    "bbox_json": "./data/bbox_coordinates.json",
                    "image_extensions": [".jpg", ".npy"],
                    "mask_suffix": "_Segmentation.png"
                }
            },
            "output_config": {
                "base_output_dir": "./results",
                "subdirs": {
                    "segmentation": "segmentation",
                    "adversarial_full": "adversarial/full_image",
                    "adversarial_local": "adversarial/local",
                    "perturbation_eval": "perturbation_evaluation",
                    "results": "results",
                    "visualizations": "visualizations"
                },
                "auto_create_timestamp_dir": True,
                "save_formats": ["csv"],
                "auto_save_interval": 5
            }
        }

    def get_model_config(self, model_name: str) -> Dict[str, Any]:
        return self.model_config.get(model_name, list(self.model_config.values())[0])

    def get_dataset_config(self, dataset_name: str) -> Dict[str, Any]:
        datasets = self.dataset_config.get("datasets", {})
        perturbation_datasets = self.dataset_config.get("perturbation_datasets", {})
        if dataset_name in datasets:
            return datasets[dataset_name]
        if dataset_name in perturbation_datasets:
            return perturbation_datasets[dataset_name]
        return list(datasets.values())[0] if datasets else self._get_default_dataset_config()["datasets"]["isic_2016"]

    def get_output_config(self) -> Dict[str, Any]:
        return self.dataset_config.get("output_config", self._get_default_dataset_config()["output_config"])

# -------------------- è¯„ä¼°æŒ‡æ ‡ --------------------
def calculate_iou(pred_mask, gt_mask):
    pred_bin = (pred_mask > 0.5).astype(np.float32)
    gt_bin = (gt_mask > 0.5).astype(np.float32)
    intersection = np.sum(pred_bin * gt_bin)
    union = np.sum(pred_bin) + np.sum(gt_bin) - intersection
    return intersection / union if union != 0 else 1.0 if np.sum(pred_bin) == 0 else 0.0

def calculate_dice(pred_mask, gt_mask):
    pred_bin = (pred_mask > 0.5).astype(np.float32)
    gt_bin = (gt_mask > 0.5).astype(np.float32)
    intersection = np.sum(pred_bin * gt_bin)
    total = np.sum(pred_bin) + np.sum(gt_bin)
    return (2.0 * intersection) / total if total != 0 else 1.0 if intersection == 0 else 0.0

def evaluate_segmentation(pred_mask, gt_mask):
    if isinstance(pred_mask, torch.Tensor):
        pred_mask = pred_mask.detach().cpu().numpy()
    if isinstance(gt_mask, torch.Tensor):
        gt_mask = gt_mask.detach().cpu().numpy()
    pred_mask = pred_mask.squeeze()
    gt_mask = gt_mask.squeeze()
    return calculate_iou(pred_mask, gt_mask), calculate_dice(pred_mask, gt_mask)

# -------------------- å¯¹æŠ—æ”»å‡»å®ç° --------------------
LEVEL_TO_EPSILON = {1: 2/255, 2: 4/255, 3: 6/255, 4: 8/255, 5: 10/255}
LEVEL_TO_ITERS = {1: 3, 2: 5, 3: 7, 4: 10, 5: 15}

def fgsm_attack(model, img_tensor, prompt, mask_tensor, epsilon):
    img_adv = img_tensor.clone().detach().requires_grad_(True).to(model.device)
    model.train()
    pred_masks, loss = model(img_adv, prompt, mask_tensor)
    assert loss is not None, "[FGSM] æ¨¡å‹æœªè¿”å› lossï¼Œæ— æ³•è®¡ç®—å¯¹æŠ—æ”»å‡»"
    # print('grad is', img_adv.grad)  # æˆ–è€… img_adv.grad.data
    # exit(0)
    model.zero_grad()
    loss.backward()
    grad_sign = img_adv.grad.sign()
    result = torch.clamp(img_adv + epsilon * grad_sign, 0, 1)
    return result.detach()

def pgd_attack(model, img_tensor, prompt, mask_tensor, epsilon, iters=10):
    img_adv = img_tensor.clone().detach().to(model.device)
    img_adv = torch.clamp(img_adv + torch.empty_like(img_adv).uniform_(-epsilon, epsilon), 0, 1)
    model.train()
    for _ in range(iters):
        img_adv = img_adv.clone().detach().requires_grad_(True)
        pred_masks, loss = model(img_adv, prompt, mask_tensor)
        assert loss is not None, "[PGD] æ¨¡å‹æœªè¿”å› lossï¼Œæ— æ³•è®¡ç®—å¯¹æŠ—æ”»å‡»"
        model.zero_grad()
        loss.backward()
        grad_sign = img_adv.grad.sign()
        img_adv = torch.clamp(img_adv + (epsilon / iters) * grad_sign, img_tensor - epsilon, img_tensor + epsilon)
        img_adv = torch.clamp(img_adv, 0, 1).detach()
    return img_adv

# -------------------- æ•°æ®åŠ è½½ --------------------
def load_image(img_path: str, model_name: str = None) -> Tuple[np.ndarray, torch.Tensor, str]:
    if img_path.endswith(".npy"):
        img_array = np.load(img_path)
        if len(img_array.shape) == 2:
            img_array = np.stack([img_array] * 3, axis=-1)
        img = img_array.astype(np.uint8)
    else:
        img = cv2.imread(img_path)
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

    original_size = img.shape[:2]
    # # SAM-Med2D ç‰¹æ®Šå¤„ç†ï¼šè°ƒæ•´åˆ°256Ã—256
    if model_name == "sammed2d":
        img = cv2.resize(img, (256, 256), interpolation=cv2.INTER_LINEAR)
        print(f"ğŸ“ [SAM-Med2D] å›¾åƒè°ƒæ•´: {original_size} â†’ (256, 256)")
        
    img_tensor = torch.from_numpy(img).permute(2, 0, 1).float() / 255.0
    img_tensor = img_tensor.unsqueeze(0)
    return img, img_tensor, os.path.basename(img_path), original_size

def load_mask(mask_path: str, model_name: str = None) -> torch.Tensor:
    mask = cv2.imread(mask_path, 0)
    mask = (mask > 0).astype(np.float32)
    if model_name == "sammed2d":
        mask = cv2.resize(mask, (256, 256), interpolation=cv2.INTER_NEAREST)
        # print(f"ğŸ“ [SAM-Med2D] æ©ç è°ƒæ•´: {original_size} â†’ (256, 256)")
    
    mask_tensor = torch.from_numpy(mask).unsqueeze(0).unsqueeze(0)
    return mask_tensor

def load_image_sammed2d(img_path: str) -> Tuple[np.ndarray, torch.Tensor, str]:
    """SAM-Med2Dä¸“ç”¨åŠ è½½ï¼šä¿æŒä¸ç‹¬ç«‹å®éªŒå®Œå…¨ä¸€è‡´çš„æ•°æ®è·¯å¾„"""
    # âœ… åŠ è½½uint8å›¾åƒï¼ˆä¸ç‹¬ç«‹å®éªŒå®Œå…¨ä¸€è‡´ï¼‰
    if img_path.endswith(".npy"):
        img_array = np.load(img_path)
        if len(img_array.shape) == 2:
            img_array = np.stack([img_array] * 3, axis=-1)
        img_np = img_array.astype(np.uint8)
    else:
        img = cv2.imread(img_path)
        img_np = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    
    # âœ… resizeåˆ°256x256ï¼ˆä¸ç‹¬ç«‹å®éªŒå®Œå…¨ä¸€è‡´ï¼‰
    img_np = cv2.resize(img_np, (256, 256), interpolation=cv2.INTER_LINEAR)
    
    # âœ… è½¬æ¢ä¸º[0,1]tensorç”¨äºå¯¹æŠ—æ”»å‡»æ¢¯åº¦è®¡ç®—
    img_tensor = torch.from_numpy(img_np).permute(2, 0, 1).float() / 255.0
    img_tensor = img_tensor.unsqueeze(0)
    
    return img_np, img_tensor, os.path.basename(img_path)

# def load_image_sammed2d(img_path: str) -> Tuple[np.ndarray, torch.Tensor, str]:
#     """ä¸“ä¸º SAM-Med2D è®¾è®¡çš„å›¾åƒåŠ è½½å‡½æ•°ï¼Œä½¿ç”¨å®˜æ–¹é¢„å¤„ç†ï¼ˆä¸é™¤ä»¥255ï¼‰"""
#     from segment_anything.utils.transforms import ResizeLongestSide

#     transform = ResizeLongestSide(256)

#     if img_path.endswith(".npy"):
#         img_array = np.load(img_path)
#         if len(img_array.shape) == 2:
#             img_array = np.stack([img_array] * 3, axis=-1)
#         img = img_array.astype(np.uint8)
#     else:
#         img = cv2.imread(img_path)
#         img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

#     # âœ… ä½¿ç”¨ SAM å®˜æ–¹é¢„å¤„ç†ï¼Œä¸é™¤ä»¥255
#     input_image = transform.apply_image(img)
#     input_image_torch = torch.as_tensor(input_image, device="cpu").permute(2, 0, 1).unsqueeze(0).float()
#     return img, input_image_torch, os.path.basename(img_path)

# -------------------- ç»“æœè®°å½•å™¨ --------------------
class IoURecorder:
    def __init__(self, save_path: str, auto_save_interval: int = 5):
        self.results = []
        self.save_path = save_path
        self.auto_save_interval = auto_save_interval
        self.save_counter = 0
        self.processed_images = set()
        os.makedirs(os.path.dirname(save_path), exist_ok=True)
        print(f"ğŸ“ ç»“æœå°†ä¿å­˜åˆ°: {save_path}")

    def add_result(self, **kwargs):
        kwargs["timestamp"] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        self.results.append(kwargs)
        if "image_name" in kwargs:
            self.processed_images.add(kwargs["image_name"])
        self.save_counter += 1
        if self.auto_save_interval > 0 and self.save_counter % self.auto_save_interval == 0:
            self.save_results(quiet=True)

    def save_results(self, quiet=False):
        if not self.results:
            if not quiet:
                print("âš ï¸ æ²¡æœ‰ç»“æœå¯ä¿å­˜")
            return
        df = pd.DataFrame(self.results)
        if self.save_path.endswith('.csv'):
            df.to_csv(self.save_path, index=False, float_format='%.6f')
        elif self.save_path.endswith('.xlsx'):
            with pd.ExcelWriter(self.save_path, engine='openpyxl') as writer:
                df.to_excel(writer, sheet_name='Results', index=False, float_format='%.6f')
        if not quiet:
            print(f"âœ… ç»“æœå·²ä¿å­˜åˆ°: {self.save_path}")

# -------------------- å¯è§†åŒ–ä¿å­˜ --------------------
def save_segmentation_result(img, bbox, pred_mask, save_path, iou_score=None, dice_score=None):
    os.makedirs(os.path.dirname(save_path), exist_ok=True)
    fig, ax = plt.subplots(1, 2, figsize=(12, 5))
    ax[0].imshow(img)
    if bbox is not None:
        x0, y0, x1, y1 = bbox
        ax[0].add_patch(plt.Rectangle((x0, y0), x1 - x0, y1 - y0, edgecolor="blue", facecolor="none", lw=2))
    ax[0].set_title("Input + Bounding Box", fontsize=12)
    ax[0].axis("off")
    ax[1].imshow(img)
    ax[1].imshow(pred_mask.squeeze(), alpha=0.5, cmap="jet")
    title = "Segmentation Result"
    if iou_score is not None and dice_score is not None:
        title += f"\nIoU: {iou_score:.4f}, Dice: {dice_score:.4f}"
    ax[1].set_title(title, fontsize=12)
    ax[1].axis("off")
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches="tight")
    plt.close()
    print(f"ğŸ–¼ï¸ ä¿å­˜åˆ†å‰²ç»“æœ: {os.path.basename(save_path)}")

def save_adversarial_result(img, adv_img, bbox, pred_mask, save_path,
                            original_iou=None, adversarial_iou=None, iou_drop=None,
                            original_dice=None, adversarial_dice=None, dice_drop=None):
    os.makedirs(os.path.dirname(save_path), exist_ok=True)
    fig, ax = plt.subplots(1, 3, figsize=(18, 5))
    ax[0].imshow(img)
    if bbox is not None:
        x0, y0, x1, y1 = bbox
        ax[0].add_patch(plt.Rectangle((x0, y0), x1 - x0, y1 - y0, edgecolor="blue", facecolor="none", lw=2))
    title_orig = "Original Image"
    if original_iou is not None:
        title_orig += f"\nIoU: {original_iou:.4f}, Dice: {original_dice:.4f}"
    ax[0].set_title(title_orig, fontsize=11)
    ax[0].axis("off")
    ax[1].imshow(adv_img)
    ax[1].set_title("Adversarial Image", fontsize=11)
    ax[1].axis("off")
    ax[2].imshow(adv_img)
    ax[2].imshow(pred_mask.squeeze(), alpha=0.5, cmap="jet")
    title_adv = "Adversarial Segmentation"
    if adversarial_iou is not None:
        title_adv += f"\nIoU: {adversarial_iou:.4f}, Dice: {adversarial_dice:.4f}"
    if iou_drop is not None:
        title_adv += f"\nDrop: IoU {iou_drop:.4f}, Dice {dice_drop:.4f}"
    ax[2].set_title(title_adv, fontsize=11)
    ax[2].axis("off")
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches="tight")
    plt.close()
    print(f"ğŸ–¼ï¸ ä¿å­˜å¯¹æŠ—ç»“æœ: {os.path.basename(save_path)}")

# -------------------- ä¸»æµç¨‹ --------------------
def setup_output_directories(output_config: Dict[str, Any], output_root: Optional[str] = None, dataset_name: str = ""):
    base_dir = output_root or output_config.get("base_output_dir", "./results")
    
    # åªæœ‰æœªæŒ‡å®š output_root æ—¶æ‰è‡ªåŠ¨åˆ›å»ºæ—¶é—´æˆ³ç›®å½•
    if output_root is None and output_config.get("auto_create_timestamp_dir", True):
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        dir_name = f"{timestamp}_{dataset_name}" if dataset_name else timestamp
        base_dir = os.path.join(base_dir, dir_name)
    
    os.makedirs(base_dir, exist_ok=True)
    print(f"ğŸ“ åˆ›å»ºè¾“å‡ºç›®å½•: {base_dir}")
    subdirs = {}
    for key, subdir in output_config.get("subdirs", {}).items():
        path = os.path.join(base_dir, subdir)
        os.makedirs(path, exist_ok=True)
        subdirs[key] = path
        print(f"   ğŸ“‚ {key}: {path}")
    return base_dir, subdirs

def collect_dataset_images(dataset_config: Dict[str, Any]):
    img_dir = dataset_config["resized_img_dir"]
    mask_dir = dataset_config["resized_mask_dir"]
    bbox_json = dataset_config["bbox_json"]
    extensions = dataset_config.get("image_extensions", [".jpg", ".npy",".png"])
    mask_suffix = dataset_config.get("mask_suffix", "_Segmentation.png")

    print(f"ğŸ” æŸ¥æ‰¾æ•°æ®é›†:")
    print(f"   å›¾åƒç›®å½•: {img_dir}")
    print(f"   æ©ç ç›®å½•: {mask_dir}")
    print(f"   è¾¹ç•Œæ¡†æ–‡ä»¶: {bbox_json}")

    if not os.path.exists(img_dir) or not os.path.exists(mask_dir):
        print("âŒ å›¾åƒæˆ–æ©ç ç›®å½•ä¸å­˜åœ¨")
        return []

    bbox_dict = {}
    if os.path.exists(bbox_json):
        with open(bbox_json, 'r') as f:
            bbox_dict = json.load(f)
        print(f"âœ… åŠ è½½è¾¹ç•Œæ¡†æ•°æ®: {len(bbox_dict)} ä¸ª")

    valid_images = []
    for img_name in os.listdir(img_dir):
        if not any(img_name.endswith(ext) for ext in extensions):
            continue
        base_name = os.path.splitext(img_name)[0]
        mask_name = f"{base_name}{mask_suffix}"
        mask_path = os.path.join(mask_dir, mask_name)
        if not os.path.exists(mask_path):
            continue
        if bbox_dict and mask_name not in bbox_dict:
            continue
        valid_images.append({
            "img_name": img_name,
            "base_name": base_name,
            "mask_name": mask_name,
            "img_path": os.path.join(img_dir, img_name),
            "mask_path": mask_path,
            "bbox": bbox_dict.get(mask_name, None)
        })
    print(f"âœ… æ‰¾åˆ°æœ‰æ•ˆå›¾åƒå¯¹: {len(valid_images)} å¯¹")
    return valid_images

def run_adversarial_evaluation(model, valid_images, args, output_dirs, recorder):
    print(f"\nğŸš€ å¼€å§‹å¯¹æŠ—æ”»å‡»è¯„ä¼°...")
    processed_count = 0
    start_time = time.time()
    images_to_process = valid_images#[:min(args.max_images or len(valid_images), 3 if args.debug else len(valid_images))]
    for img_info in images_to_process:
        # try:      		
        # if args.model_name == "sammed2d":
        #     img_np, img_tensor, filename = load_image_sammed2d(img_info["img_path"])
        # else:
        if args.model_name == "sammed2d":
            img_np, img_tensor, filename = load_image_sammed2d(img_info["img_path"])
        else:
            img_np, img_tensor, filename, _ = load_image(img_info["img_path"], args.model_name)
        
        # img_np, img_tensor, filename, _ = load_image(img_info["img_path"], args.model_name)
        
        mask_tensor = load_mask(img_info["mask_path"], args.model_name)
        img_tensor = img_tensor.to(args.device)
        gt_mask = mask_tensor.squeeze().numpy()
        bbox = img_info["bbox"] if model.prompt_required else None

        # åœ¨ pipeline.py çš„ run_adversarial_evaluation() é‡Œï¼Œå¤„ç†å•å¼ å›¾çš„ä½ç½®æ’ï¼š
        print("===", img_info["base_name"], "===")
        print("bbox from json :", img_info["bbox"])
        print("img range      :", img_tensor.min().item(), "~", img_tensor.max().item())
        print("mask range     :", mask_tensor.min().item(), "~", mask_tensor.max().item())
        # exit(0)

        image_start_time = time.time()
        with torch.no_grad():
            pred_mask = model(img_tensor, bbox)
            original_iou, original_dice = evaluate_segmentation(pred_mask, gt_mask)

        recorder.add_result(
            image_name=img_info["base_name"],
            attack_type=None,
            level=None,
            original_iou=original_iou,
            original_dice=original_dice,
            processing_time=time.time() - image_start_time
        )

        if not args.no_visualizations:
            pred_mask_binary = pred_mask.squeeze().cpu().numpy() > 0.5
            seg_save_path = os.path.join(output_dirs["segmentation"], f"{img_info['base_name']}_seg.png")
            save_segmentation_result(img_np, bbox, pred_mask_binary, seg_save_path, original_iou, original_dice)

        for attack_type in args.attack_types:
            for level in args.levels:
                epsilon = LEVEL_TO_EPSILON[level]
                iters = LEVEL_TO_ITERS[level]
                if attack_type == "fgsm":
                    adv_tensor = fgsm_attack(model, img_tensor, bbox, mask_tensor, epsilon)
                else:
                    adv_tensor = pgd_attack(model, img_tensor, bbox, mask_tensor, epsilon, iters)

                with torch.no_grad():
                    adv_pred = model(adv_tensor, bbox)
                    adv_iou, adv_dice = evaluate_segmentation(adv_pred, gt_mask)
                    iou_drop = original_iou - adv_iou
                    dice_drop = original_dice - adv_dice

                recorder.add_result(
                    image_name=img_info["base_name"],
                    attack_type=attack_type,
                    level=level,
                    epsilon=epsilon,
                    iterations=iters if attack_type == "pgd" else 1,
                    original_iou=original_iou,
                    adversarial_iou=adv_iou,
                    iou_drop=iou_drop,
                    original_dice=original_dice,
                    adversarial_dice=adv_dice,
                    dice_drop=dice_drop
                )

                if not args.no_visualizations:
                    adv_pred_binary = adv_pred.squeeze().cpu().numpy() > 0.5
                    adv_np = (adv_tensor.squeeze().permute(1, 2, 0).cpu().numpy() * 255).astype(np.uint8)
                    adv_save_path = os.path.join(output_dirs["adversarial_full"], attack_type, str(level), f"{img_info['base_name']}_adv.png")
                    save_adversarial_result(img_np, adv_np, bbox, adv_pred_binary, adv_save_path,
                                            original_iou, adv_iou, iou_drop, original_dice, adv_dice, dice_drop)

        processed_count += 1
        # except Exception as e:
        #     print(f"âš ï¸ è·³è¿‡{img_info['img_name']}: {e}")
        #     continue

    recorder.save_results()
    print(f"\nğŸ‰ å¯¹æŠ—æ”»å‡»è¯„ä¼°å®Œæˆ! å¤„ç†å›¾åƒ: {processed_count} å¼ , ç»“æœæ–‡ä»¶: {recorder.save_path}")

# -------------------- æ‰°åŠ¨æ•°æ®é›†è¯„ä¼° --------------------
def extract_perturbation_info(img_path: str):
    parts = img_path.replace('\\', '/').split('/')
    filename = os.path.basename(img_path)
    base_name = os.path.splitext(filename)[0]
    if len(parts) >= 3:
        level_str = parts[-2]
        perturbation_type = parts[-3]
        if level_str.isdigit():
            level = int(level_str)
            if 1 <= level <= 5:
                return base_name, perturbation_type, level
    return base_name, None, None

def evaluate_perturbation_dataset(pert_dataset_name, perturbation_path, model, args, output_dirs):
    print(f"\nğŸ” å¼€å§‹è¯„ä¼°æ‰°åŠ¨æ•°æ®é›†: {perturbation_path}")
    config_loader = ConfigLoader(args.model_config, args.dataset_config)
    # original_dataset_config = config_loader.get_dataset_config("isic_2016")
    original_dataset_config = config_loader.get_dataset_config(pert_dataset_name[:-10])
    resized_img_dir = original_dataset_config["resized_img_dir"]
    resized_mask_dir = original_dataset_config["resized_mask_dir"]
    bbox_json = original_dataset_config["bbox_json"]

    with open(bbox_json, "r") as f:
        bbox_dict = json.load(f)

    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    perturbation_results_file = os.path.join(output_dirs["results"], f"perturbation_results_{timestamp}.csv")
    perturbation_recorder = IoURecorder(perturbation_results_file, 10)
    PERTURBATION_OUTPUT = os.path.join(output_dirs["perturbation_eval"])
    os.makedirs(PERTURBATION_OUTPUT, exist_ok=True)

    jpg_files = []
    
    # æ”¯æŒ.jpgå’Œ.pngä¸¤ç§æ ¼å¼ï¼ˆsegmentation_generate_perb_all_V9_adpative_efficient.pyç”Ÿæˆçš„æ˜¯.pngï¼‰
    supported_extensions = ('.jpg', '.jpeg', '.png')
    for root, dirs, files in os.walk(perturbation_path):
        for file in files:
            if file.lower().endswith(supported_extensions):
                jpg_files.append(os.path.join(root, file))
    print(f"ğŸ“Š æ‰¾åˆ° {len(jpg_files)} å¼ æ‰°åŠ¨å›¾åƒï¼ˆæ”¯æŒæ ¼å¼: {supported_extensions}ï¼‰")
    
    # å¦‚æœæä¾›äº†æ•°æ®åˆ’åˆ†æ–‡ä»¶ï¼Œåªè¯„ä¼°æµ‹è¯•é›†
    if args.data_split_json and os.path.exists(args.data_split_json):
        with open(args.data_split_json, 'r') as f:
            split_info = json.load(f)
        test_files = set(split_info.get("test_files", []))
        original_count = len(jpg_files)
        # ä»æ–‡ä»¶è·¯å¾„ä¸­æå– base_name è¿›è¡Œè¿‡æ»¤
        filtered_files = []
        for img_path in jpg_files:
            base_name, _, _ = extract_perturbation_info(img_path)
            if base_name in test_files:
                filtered_files.append(img_path)
        jpg_files = filtered_files
        print(f"   ğŸ“‹ æ ¹æ®æ•°æ®åˆ’åˆ†æ–‡ä»¶è¿‡æ»¤: {original_count} â†’ {len(jpg_files)} (ä»…æµ‹è¯•é›†)")

    processed_count = 0
    failed_count = 0
    start_time = time.time()
    # åœ¨ evaluate_perturbation_dataset() é‡Œï¼Œfor img_path in jpg_files: ä¹‹å‰æ’å…¥
    # if args.debug:
    #     print("ğŸ§ª è°ƒè¯•æ¨¡å¼ï¼šæ‰°åŠ¨è¯„ä¼°åªå¤„ç†å‰ 3 å¼ å›¾")
    #     jpg_files = jpg_files[:3]
	
    if args.debug:
        print("ğŸ§ª è°ƒè¯•æ¨¡å¼ï¼šæ™ºèƒ½é‡‡æ ·ï¼Œç¡®ä¿è¦†ç›–æ‰€æœ‰æ‰°åŠ¨ç±»å‹")
        
        from collections import defaultdict
        grouped_files = defaultdict(lambda: defaultdict(list))
        
        # æå–å¹¶åˆ†ç»„
        for img_path in jpg_files:
            base_name, ptype, level = extract_perturbation_info(img_path)
            if ptype and level:
                grouped_files[ptype][level].append(img_path)
        
        # ä»æ¯ä¸ª ç±»å‹-çº§åˆ« ç»„åˆä¸­å–Nå¼ 
        debug_files = []
        samples_per_combination = local_share_var.debug_custom_number  # æ§åˆ¶æ•°é‡
        
        for ptype in sorted(grouped_files.keys()):
            print(f"\n  ğŸ”¹ {ptype}:")
            for level in sorted(grouped_files[ptype].keys()):
                if grouped_files[ptype][level]:
                    # å–è¯¥ç»„åˆçš„å‰Nå¼ å›¾
                    sorted_files = sorted(grouped_files[ptype][level])  # â† åŠ è¿™è¡Œ
                    selected = sorted_files[:samples_per_combination]
                    # selected = grouped_files[ptype][level][:samples_per_combination]
                    debug_files.extend(selected)
                    print(f"     Level {level}: {len(selected)}/{len(grouped_files[ptype][level])} å¼ ")
        
        jpg_files = debug_files
        print(f"\nğŸ§ª è°ƒè¯•æ¨¡å¼æ€»è®¡ï¼š{len(jpg_files)} å¼ å›¾åƒ")
        
    for img_path in jpg_files:
        base_name, perturbation_type, level = extract_perturbation_info(img_path)
        
        if perturbation_type is None or level is None:
            failed_count += 1
            continue
				
        # mask_name = f"{base_name}_Segmentation.png"
        mask_suffix = original_dataset_config["mask_suffix"]
        mask_name = f"{base_name}{mask_suffix}"
        mask_path = os.path.join(resized_mask_dir, mask_name)
        if not os.path.exists(mask_path) or mask_name not in bbox_dict:
            failed_count += 1
            continue

        original_bbox = bbox_dict[mask_name]
        if args.model_name == "sammed2d":
        	img_np, img_tensor, filename = load_image_sammed2d(img_path)
        else:
        	img_np, img_tensor, filename, original_size = load_image(img_path, args.model_name)
		
        bbox = original_bbox  # å…¶ä»–æ¨¡å‹ç›´æ¥ä½¿ç”¨åŸå§‹è¾¹ç•Œæ¡†
        
        mask_tensor = load_mask(mask_path, args.model_name)
        
        img_tensor = img_tensor.to(args.device)
        gt_mask = mask_tensor.squeeze().numpy()

        # original_img_path = os.path.join(resized_img_dir, f"{base_name}.jpg")
        # if not os.path.exists(original_img_path):
        #     original_img_path = os.path.join(resized_img_dir, f"{base_name}.npy")

        # æ ¹æ®é…ç½®åŠ¨æ€æŸ¥æ‰¾
        image_extensions = original_dataset_config["image_extensions"]
        original_img_path = None
        for ext in image_extensions:
            ext_with_dot = ext if ext.startswith('.') else f'.{ext}'
            test_path = os.path.join(resized_img_dir, f"{base_name}{ext_with_dot}")
            if os.path.exists(test_path):
                original_img_path = test_path
                break
				
        original_iou = original_dice = None
        if os.path.exists(original_img_path):
            _, original_img_tensor, _, _ = load_image(original_img_path, args.model_name)
            original_img_tensor = original_img_tensor.to(args.device)
            with torch.no_grad():
                original_pred = model(original_img_tensor, bbox)
                original_iou, original_dice = evaluate_segmentation(original_pred, gt_mask)

        image_start_time = time.time()
        with torch.no_grad():
            pred_mask = model(img_tensor, bbox)
            perturb_iou, perturb_dice = evaluate_segmentation(pred_mask, gt_mask)
        processing_time = time.time() - image_start_time

        iou_drop = original_iou - perturb_iou if original_iou is not None else None
        dice_drop = original_dice - perturb_dice if original_dice is not None else None

        perturbation_recorder.add_result(
            image_name=base_name,
            attack_type=perturbation_type,
            level=level,
            epsilon=None,
            iterations=None,
            original_iou=original_iou,
            adversarial_iou=perturb_iou,
            iou_drop=iou_drop,
            original_dice=original_dice,
            adversarial_dice=perturb_dice,
            dice_drop=dice_drop,
            processing_time=processing_time
        )

        if not args.no_visualizations:
            pred_mask_binary = pred_mask.squeeze().cpu().numpy() > 0.5
            save_dir = os.path.join(PERTURBATION_OUTPUT, perturbation_type, str(level))
            os.makedirs(save_dir, exist_ok=True)
            save_path = os.path.join(save_dir, f"{base_name}_perturbation.png")
            save_segmentation_result(img_np, bbox, pred_mask_binary, save_path, perturb_iou, perturb_dice)

        processed_count += 1
        if processed_count % 20 == 0:
            print(f"   å·²å¤„ç†: {processed_count}/{len(jpg_files)} ({perturbation_type}-L{level}, IoU: {perturb_iou:.3f})")
        # except Exception as e:
        #     failed_count += 1
        #     continue

    perturbation_recorder.save_results()
    total_time = time.time() - start_time
    print(f"\nâœ… æ‰°åŠ¨æ•°æ®é›†è¯„ä¼°å®Œæˆ! æˆåŠŸå¤„ç†: {processed_count} å¼ , å¤±è´¥: {failed_count} å¼ , ç»“æœæ–‡ä»¶: {perturbation_results_file}")

    return perturbation_results_file

# -------------------- ä¸»å…¥å£ --------------------
# ----------- ä»…æ›¿æ¢åŸæ¥çš„ main() å‡½æ•° -----------
def main():
    args = get_parser().parse_args()
    if args.no_visualizations:
        args.save_visualizations = False

    print(f"ğŸš€ é€šç”¨åˆ†å‰²æ¨¡å‹å¯¹æŠ—æ”»å‡»ç³»ç»Ÿå¯åŠ¨")
    print(f"   è®¾å¤‡: {args.device}, æ¨¡å‹: {args.model_name}, è¯„ä¼°æ¨¡å¼: {args.eval_mode}")

    config_loader = ConfigLoader(args.model_config, args.dataset_config)
    model_cfg = config_loader.get_model_config(args.model_name)
    output_cfg = config_loader.get_output_config()
    model = create_model(args.model_name, args.device, model_cfg)
    
    # â˜… åŠ è½½å¾®è°ƒæƒé‡ (ä¿®å¤ç‰ˆ - æ”¯æŒLoRA)
    if args.finetune_checkpoint:
        if os.path.exists(args.finetune_checkpoint):
            print(f"\n{'='*70}")
            print(f"ğŸ”§ åŠ è½½å¾®è°ƒæƒé‡: {args.finetune_checkpoint}")
            print(f"{'='*70}")
            
            checkpoint = torch.load(args.finetune_checkpoint, map_location=args.device)
            ft_config = checkpoint.get("config", {})
            ft_strategy = ft_config.get("strategy", "unknown")
            
            print(f"   æ£€æŸ¥ç‚¹ç­–ç•¥: {ft_strategy}")
            print(f"   æ£€æŸ¥ç‚¹Epoch: {checkpoint.get('epoch', 'N/A')}")
            
            # â˜… å¦‚æœæ˜¯LoRAå¾®è°ƒï¼Œéœ€è¦å…ˆé‡å»ºLoRAç»“æ„
            if ft_strategy == "lora":
                print(f"\n   ğŸ“Œ æ£€æµ‹åˆ°LoRAæ£€æŸ¥ç‚¹ï¼Œé‡å»ºLoRAç»“æ„...")
                try:
                    from finetune_utils import FinetuneConfig, setup_finetune
                    
                    # âœ… å®Œæ•´æ¢å¤LoRAé…ç½®ï¼ˆåŒ…æ‹¬target_moduleså’Œdropoutï¼‰
                    lora_config = FinetuneConfig(
                        strategy="lora",
                        lora_r=ft_config.get("lora_r", 8),
                        lora_alpha=ft_config.get("lora_alpha", 16),
                        lora_dropout=ft_config.get("lora_dropout", 0.1),
                        lora_target_modules=ft_config.get("lora_target_modules", ["q_proj", "v_proj"]),
                    )
                    print(f"   LoRAé…ç½®: r={lora_config.lora_r}, alpha={lora_config.lora_alpha}")
                    print(f"   target_modules={lora_config.lora_target_modules}")
                    model = setup_finetune(model, args.model_name, lora_config)
                    print(f"   âœ… LoRAç»“æ„é‡å»ºæˆåŠŸ")
                except Exception as e:
                    print(f"   âŒ LoRAç»“æ„é‡å»ºå¤±è´¥: {e}")
                    import traceback
                    traceback.print_exc()
                    print(f"   âš ï¸ å›é€€åˆ°ç›´æ¥åŠ è½½ï¼ŒLoRAæƒé‡å¯èƒ½ä¸¢å¤±!")
            
            # åŠ è½½æƒé‡
            state_dict = checkpoint.get("model_state_dict", checkpoint)
            
            # âœ… å¦‚æœæ˜¯LoRAï¼Œå¤„ç†PEFTæ¨¡å‹çš„é”®åæ˜ å°„é—®é¢˜
            if ft_strategy == "lora":
                # è·å–å½“å‰æ¨¡å‹çš„é”®å
                model_keys = set(model.state_dict().keys())
                checkpoint_keys = set(state_dict.keys())
                
                # æ£€æŸ¥æ˜¯å¦éœ€è¦é”®åè½¬æ¢
                # PEFTæ¨¡å‹å¯èƒ½æœ‰ base_model.model. å‰ç¼€
                needs_mapping = False
                if any('base_model.model.' in k for k in model_keys) and not any('base_model.model.' in k for k in checkpoint_keys):
                    needs_mapping = True
                    print(f"   ğŸ“Œ æ£€æµ‹åˆ°é”®åä¸åŒ¹é…ï¼Œè¿›è¡ŒPEFTé”®åæ˜ å°„...")
                    # checkpointä¸­çš„é”® -> åŠ ä¸Š base_model.model. å‰ç¼€
                    new_state_dict = {}
                    for k, v in state_dict.items():
                        if k.startswith('model.'):
                            # model.xxx -> base_model.model.xxx (å»æ‰å¼€å¤´çš„model.)
                            new_key = 'base_model.' + k
                        else:
                            new_key = 'base_model.model.' + k
                        new_state_dict[new_key] = v
                    state_dict = new_state_dict
                elif not any('base_model.model.' in k for k in model_keys) and any('base_model.model.' in k for k in checkpoint_keys):
                    needs_mapping = True
                    print(f"   ğŸ“Œ æ£€æµ‹åˆ°é”®åä¸åŒ¹é…ï¼Œè¿›è¡Œåå‘PEFTé”®åæ˜ å°„...")
                    # checkpointä¸­æœ‰ base_model.model. å‰ç¼€ -> å»æ‰
                    new_state_dict = {}
                    for k, v in state_dict.items():
                        if k.startswith('base_model.model.'):
                            new_key = k.replace('base_model.model.', 'model.')
                        elif k.startswith('base_model.'):
                            new_key = k.replace('base_model.', '')
                        else:
                            new_key = k
                        new_state_dict[new_key] = v
                    state_dict = new_state_dict
            
            # åˆ†æåŠ è½½æƒ…å†µ
            missing_keys, unexpected_keys = model.load_state_dict(state_dict, strict=False)
            
            print(f"\n   ğŸ“Š æƒé‡åŠ è½½åˆ†æ:")
            print(f"      ç¼ºå¤±çš„key: {len(missing_keys)}")
            print(f"      å¤šä½™çš„key: {len(unexpected_keys)}")
            
            if len(missing_keys) > 0:
                print(f"      ç¼ºå¤±ç¤ºä¾‹: {missing_keys[:3]}")
            if len(unexpected_keys) > 0:
                print(f"      å¤šä½™ç¤ºä¾‹: {unexpected_keys[:3]}")
                
            # LoRAç‰¹æ®Šæ£€æŸ¥
            if ft_strategy == "lora":
                lora_loaded = sum(1 for k in state_dict.keys() if 'lora' in k.lower())
                lora_missing = sum(1 for k in missing_keys if 'lora' in k.lower())
                print(f"      LoRAå‚æ•°: æ£€æŸ¥ç‚¹ä¸­{lora_loaded}ä¸ª, æœªåŠ è½½{lora_missing}ä¸ª")
                if lora_missing > 0:
                    print(f"      âŒ è­¦å‘Š: LoRAæƒé‡æœªå®Œå…¨åŠ è½½!")
            
            print(f"\nâœ… å¾®è°ƒæƒé‡åŠ è½½å®Œæˆ")
            
            # âœ… ç¡®ä¿æ¨¡å‹åœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Šï¼ˆç‰¹åˆ«æ˜¯æ‰‹åŠ¨LoRAçš„æƒ…å†µï¼‰
            model = model.to(args.device)
            print(f"   æ¨¡å‹å·²ç§»è‡³è®¾å¤‡: {args.device}")
            
            if "metrics" in checkpoint:
                metrics = checkpoint["metrics"]
                print(f"   è®­ç»ƒæŒ‡æ ‡: Dice={metrics.get('dice', 'N/A'):.4f}, IoU={metrics.get('iou', 'N/A'):.4f}")
            print(f"{'='*70}\n")
        else:
            print(f"âš ï¸ å¾®è°ƒæ£€æŸ¥ç‚¹ä¸å­˜åœ¨: {args.finetune_checkpoint}ï¼Œä½¿ç”¨åŸå§‹é¢„è®­ç»ƒæ¨¡å‹")
    
    # base_output, output_dirs = setup_output_directories(output_cfg, args.output_root)

    # æŠŠ dataset_name æ‹†æˆ list
    dataset_names = [args.dataset_name] if isinstance(args.dataset_name, str) else args.dataset_name

    # â”€â”€ both æ¨¡å¼å¿…é¡»æä¾› 2 ä¸ªåå­— ----------
    if args.eval_mode == "both":
        if len(dataset_names) != 2:
            print("âŒ both æ¨¡å¼ä¸‹éœ€è¦ä¼ å…¥ 2 ä¸ªæ•°æ®é›†åï¼š--dataset_name åŸå§‹ æ‰°åŠ¨")
            return
        adv_dataset_name, pert_dataset_name = dataset_names
    else:
        adv_dataset_name = pert_dataset_name = dataset_names[0]

    if args.eval_mode == "both":
        combined_name = f"{adv_dataset_name}_vs_{pert_dataset_name}_{args.model_name}"
    else:
        combined_name = f"{dataset_names[0]}_{args.model_name}"
    
    base_output, output_dirs = setup_output_directories(output_cfg, args.output_root, combined_name)

    # 1) å¯¹æŠ—æ”»å‡»éƒ¨åˆ†
    if args.eval_mode in ["adversarial", "both"]:
        dataset_cfg = config_loader.get_dataset_config(adv_dataset_name)
        print(f"\nğŸ“Š æ”¶é›†å¯¹æŠ—æ•°æ®é›†ï¼š{adv_dataset_name}")
        valid_images = collect_dataset_images(dataset_cfg)
        
        # å¦‚æœæä¾›äº†æ•°æ®åˆ’åˆ†æ–‡ä»¶ï¼Œåªè¯„ä¼°æµ‹è¯•é›†
        if args.data_split_json and os.path.exists(args.data_split_json):
            with open(args.data_split_json, 'r') as f:
                split_info = json.load(f)
            test_files = set(split_info.get("test_files", []))
            original_count = len(valid_images)
            valid_images = [img for img in valid_images if img["base_name"] in test_files]
            print(f"   ğŸ“‹ æ ¹æ®æ•°æ®åˆ’åˆ†æ–‡ä»¶è¿‡æ»¤: {original_count} â†’ {len(valid_images)} (ä»…æµ‹è¯•é›†)")
        
        if args.debug and len(valid_images) > 3:
            valid_images = valid_images[:local_share_var.debug_custom_number]
            # print('hello')
            # exit(0)
        if valid_images:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            results_file = os.path.join(output_dirs["results"], f"results_adversarial_{timestamp}.csv")
            recorder = IoURecorder(results_file, output_cfg.get("auto_save_interval", 5))
            run_adversarial_evaluation(model, valid_images, args, output_dirs, recorder)
            # âœ¨ æ–°å¢ï¼šç”Ÿæˆæ±‡æ€»è¡¨
            generate_summary_table(results_file, output_dirs["results"])

    # 2) æ‰°åŠ¨è¯„ä¼°éƒ¨åˆ†
    if args.eval_mode in ["perturbation", "both"]:
        pert_cfg = config_loader.get_dataset_config(pert_dataset_name)
        perturbation_path = pert_cfg.get("root_path", args.perturbation_path)
        # evaluate_perturbation_dataset(pert_dataset_name, perturbation_path, model, args, output_dirs)
        # éœ€è¦è·å–æ‰°åŠ¨è¯„ä¼°çš„CSVè·¯å¾„ï¼Œä¿®æ”¹evaluate_perturbation_datasetè¿”å›å€¼
        perturbation_results_file = evaluate_perturbation_dataset(
            pert_dataset_name, perturbation_path, model, args, output_dirs
        )
        # âœ¨ æ–°å¢ï¼šç”Ÿæˆæ±‡æ€»è¡¨
        if perturbation_results_file:
            generate_summary_table(perturbation_results_file, output_dirs["results"])


    print(f"\nğŸ‰ å…¨éƒ¨å®Œæˆï¼ç»“æœä¿å­˜åœ¨: {base_output}")

# -------------------- æ±‡æ€»ç»Ÿè®¡å‡½æ•° --------------------
def generate_summary_table(csv_path: str, output_dir: str):
    """
    ä»è¯¦ç»†CSVç”Ÿæˆç±»ä¼¼Table 1çš„æ±‡æ€»è¡¨
    æ”¯æŒadversarialå’Œperturbationä¸¤ç§æ•°æ®æ ¼å¼
    """
    if not os.path.exists(csv_path):
        print(f"âš ï¸ CSVæ–‡ä»¶ä¸å­˜åœ¨: {csv_path}")
        return
    
    print(f"\nğŸ“Š æ­£åœ¨ç”Ÿæˆæ±‡æ€»ç»Ÿè®¡è¡¨...")
    df = pd.read_csv(csv_path)
    
    # ===== 1. æ™ºèƒ½è¯†åˆ«æ•°æ®æ ¼å¼å¹¶è®¡ç®—Cleanæ€§èƒ½ =====
    clean_df = df[df['attack_type'].isna()]
    
    if len(clean_df) > 0:
        # âœ… Adversarialæ¨¡å¼ï¼šæœ‰ä¸“é—¨çš„Cleanè¡Œ
        print("ğŸ“Œ æ£€æµ‹åˆ°Adversarialæ¨¡å¼æ•°æ®")
        clean_iou = clean_df['original_iou'].mean()
        clean_dice = clean_df['original_dice'].mean()
        corrupted_df = df[df['attack_type'].notna()]
    else:
        # âœ… Perturbationæ¨¡å¼ï¼šCleanæ•°æ®åœ¨original_iouåˆ—ä¸­
        print("ğŸ“Œ æ£€æµ‹åˆ°Perturbationæ¨¡å¼æ•°æ®")
        corrupted_df = df[df['attack_type'].notna()]
        
        if len(corrupted_df) == 0:
            print("âš ï¸ æœªæ‰¾åˆ°ä»»ä½•æ•°æ®")
            return
        
        # ä»original_iou/diceåˆ—æå–Cleanæ€§èƒ½ï¼ˆæ‰€æœ‰è¡Œçš„å¹³å‡å€¼ï¼‰
        clean_iou = corrupted_df['original_iou'].mean()
        clean_dice = corrupted_df['original_dice'].mean()
    
    print(f"âœ… Cleanæ€§èƒ½: IoU={clean_iou:.4f}, Dice={clean_dice:.4f}")
    
    # ===== 2. æŒ‰corruptionç±»å‹åˆ†ç»„ç»Ÿè®¡ =====
    if len(corrupted_df) == 0:
        print("âš ï¸ æœªæ‰¾åˆ°æ‰°åŠ¨æ•°æ®")
        return
    
    # æŒ‰attack_typeåˆ†ç»„ï¼Œè®¡ç®—å¹³å‡å€¼ï¼ˆè·¨æ‰€æœ‰levelå’Œå›¾åƒï¼‰
    stats_by_type = corrupted_df.groupby('attack_type').agg({
        'adversarial_iou': 'mean',
        'adversarial_dice': 'mean',
        'iou_drop': 'mean',
        'dice_drop': 'mean'
    }).round(4)
    
    # ===== 3. è®¡ç®—æ€»ä½“å¹³å‡ =====
    avg_iou = corrupted_df['adversarial_iou'].mean()
    avg_dice = corrupted_df['adversarial_dice'].mean()
    avg_iou_drop = corrupted_df['iou_drop'].mean()
    avg_dice_drop = corrupted_df['dice_drop'].mean()
    
    # ===== 4. æ„å»ºç±»ä¼¼Table 1çš„æ±‡æ€»è¡¨ =====
    summary_rows = []
    
    # æ·»åŠ Cleanè¡Œ
    if clean_iou is not None:
        summary_rows.append({
            'Corruption_Type': 'Clean',
            'IoU': clean_iou,
            'Dice': clean_dice,
            'IoU_Drop': 0.0,
            'Dice_Drop': 0.0
        })
    
    # æ·»åŠ å„corruptionç±»å‹
    for attack_type, row in stats_by_type.iterrows():
        summary_rows.append({
            'Corruption_Type': attack_type,
            'IoU': row['adversarial_iou'],
            'Dice': row['adversarial_dice'],
            'IoU_Drop': row['iou_drop'],
            'Dice_Drop': row['dice_drop']
        })
    
    # æ·»åŠ Avgè¡Œ
    summary_rows.append({
        'Corruption_Type': 'Avg',
        'IoU': avg_iou,
        'Dice': avg_dice,
        'IoU_Drop': avg_iou_drop,
        'Dice_Drop': avg_dice_drop
    })
    
    # æ·»åŠ Î”TPè¡Œï¼ˆClean - Avgï¼‰
    if clean_iou is not None:
        delta_tp_iou = clean_iou - avg_iou
        delta_tp_dice = clean_dice - avg_dice
        summary_rows.append({
            'Corruption_Type': 'Î”TP',
            'IoU': delta_tp_iou,
            'Dice': delta_tp_dice,
            'IoU_Drop': delta_tp_iou,
            'Dice_Drop': delta_tp_dice
        })
    
    # ===== 5. ä¿å­˜å’Œæ˜¾ç¤ºæ±‡æ€»è¡¨ =====
    summary_df = pd.DataFrame(summary_rows)
    
    # ä¿å­˜æ±‡æ€»CSV
    summary_path = csv_path.replace('.csv', '_SUMMARY.csv')
    summary_df.to_csv(summary_path, index=False, float_format='%.4f')
    print(f"âœ… æ±‡æ€»è¡¨å·²ä¿å­˜: {summary_path}")
    
    # æ‰“å°åˆ°æ§åˆ¶å°
    print("\n" + "="*70)
    print("ğŸ“Š æ€§èƒ½æ±‡æ€»è¡¨ (ç±»ä¼¼Table 1æ ¼å¼)")
    print("="*70)
    print(summary_df.to_string(index=False))
    print("="*70)
    
    # ===== 6. å¯é€‰ï¼šæŒ‰levelåˆ†ç»„çš„è¯¦ç»†ç»Ÿè®¡ =====
    if 'level' in corrupted_df.columns:
        print("\nğŸ“Š æŒ‰æ‰°åŠ¨çº§åˆ«(Level)çš„è¯¦ç»†ç»Ÿè®¡:")
        level_stats = corrupted_df.groupby(['attack_type', 'level']).agg({
            'adversarial_iou': 'mean',
            'adversarial_dice': 'mean'
        }).round(4)
        print(level_stats)
        
        # ä¿å­˜è¯¦ç»†ç»Ÿè®¡
        level_stats_path = csv_path.replace('.csv', '_STATS_BY_LEVEL.csv')
        level_stats.to_csv(level_stats_path, float_format='%.4f')
        print(f"âœ… æŒ‰çº§åˆ«ç»Ÿè®¡å·²ä¿å­˜: {level_stats_path}")
    
    return summary_df
    
# -------------------- æ±‡æ€»ç»Ÿè®¡å‡½æ•° --------------------
# def generate_summary_table(csv_path: str, output_dir: str):
#     """
#     ä»è¯¦ç»†CSVç”Ÿæˆç±»ä¼¼Table 1çš„æ±‡æ€»è¡¨
#     """
#     if not os.path.exists(csv_path):
#         print(f"âš ï¸ CSVæ–‡ä»¶ä¸å­˜åœ¨: {csv_path}")
#         return
    
#     print(f"\nğŸ“Š æ­£åœ¨ç”Ÿæˆæ±‡æ€»ç»Ÿè®¡è¡¨...")
#     df = pd.read_csv(csv_path)
    
#     # ===== 1. è®¡ç®—Cleanæ€§èƒ½ =====
#     clean_df = df[df['attack_type'].isna()]
#     if len(clean_df) == 0:
#         print("âš ï¸ æœªæ‰¾åˆ°Cleanæ•°æ®ï¼ˆattack_typeä¸ºç©ºçš„è®°å½•ï¼‰")
#         clean_iou = clean_dice = None
#     else:
#         clean_iou = clean_df['original_iou'].mean()
#         clean_dice = clean_df['original_dice'].mean()
#         print(f"âœ… Cleanæ€§èƒ½: IoU={clean_iou:.4f}, Dice={clean_dice:.4f}")
    
#     # ===== 2. æŒ‰corruptionç±»å‹åˆ†ç»„ç»Ÿè®¡ =====
#     corrupted_df = df[df['attack_type'].notna()]
    
#     if len(corrupted_df) == 0:
#         print("âš ï¸ æœªæ‰¾åˆ°æ‰°åŠ¨æ•°æ®")
#         return
    
#     # æŒ‰attack_typeåˆ†ç»„ï¼Œè®¡ç®—å¹³å‡å€¼ï¼ˆè·¨æ‰€æœ‰levelå’Œå›¾åƒï¼‰
#     stats_by_type = corrupted_df.groupby('attack_type').agg({
#         'adversarial_iou': 'mean',
#         'adversarial_dice': 'mean',
#         'iou_drop': 'mean',
#         'dice_drop': 'mean'
#     }).round(4)
    
#     # ===== 3. è®¡ç®—æ€»ä½“å¹³å‡ =====
#     avg_iou = corrupted_df['adversarial_iou'].mean()
#     avg_dice = corrupted_df['adversarial_dice'].mean()
#     avg_iou_drop = corrupted_df['iou_drop'].mean()
#     avg_dice_drop = corrupted_df['dice_drop'].mean()
    
#     # ===== 4. æ„å»ºç±»ä¼¼Table 1çš„æ±‡æ€»è¡¨ =====
#     summary_rows = []
    
#     # æ·»åŠ Cleanè¡Œ
#     if clean_iou is not None:
#         summary_rows.append({
#             'Corruption_Type': 'Clean',
#             'IoU': clean_iou,
#             'Dice': clean_dice,
#             'IoU_Drop': 0.0,
#             'Dice_Drop': 0.0
#         })
    
#     # æ·»åŠ å„corruptionç±»å‹
#     for attack_type, row in stats_by_type.iterrows():
#         summary_rows.append({
#             'Corruption_Type': attack_type,
#             'IoU': row['adversarial_iou'],
#             'Dice': row['adversarial_dice'],
#             'IoU_Drop': row['iou_drop'],
#             'Dice_Drop': row['dice_drop']
#         })
    
#     # æ·»åŠ Avgè¡Œ
#     summary_rows.append({
#         'Corruption_Type': 'Avg',
#         'IoU': avg_iou,
#         'Dice': avg_dice,
#         'IoU_Drop': avg_iou_drop,
#         'Dice_Drop': avg_dice_drop
#     })
    
#     # æ·»åŠ Î”TPè¡Œï¼ˆClean - Avgï¼‰
#     if clean_iou is not None:
#         delta_tp_iou = clean_iou - avg_iou
#         delta_tp_dice = clean_dice - avg_dice
#         summary_rows.append({
#             'Corruption_Type': 'Î”TP',
#             'IoU': delta_tp_iou,
#             'Dice': delta_tp_dice,
#             'IoU_Drop': delta_tp_iou,
#             'Dice_Drop': delta_tp_dice
#         })
    
#     # ===== 5. ä¿å­˜å’Œæ˜¾ç¤ºæ±‡æ€»è¡¨ =====
#     summary_df = pd.DataFrame(summary_rows)
    
#     # ä¿å­˜æ±‡æ€»CSV
#     summary_path = csv_path.replace('.csv', '_SUMMARY.csv')
#     summary_df.to_csv(summary_path, index=False, float_format='%.4f')
#     print(f"âœ… æ±‡æ€»è¡¨å·²ä¿å­˜: {summary_path}")
    
#     # æ‰“å°åˆ°æ§åˆ¶å°
#     print("\n" + "="*70)
#     print("ğŸ“Š æ€§èƒ½æ±‡æ€»è¡¨ (ç±»ä¼¼Table 1æ ¼å¼)")
#     print("="*70)
#     print(summary_df.to_string(index=False))
#     print("="*70)
    
#     # ===== 6. å¯é€‰ï¼šæŒ‰levelåˆ†ç»„çš„è¯¦ç»†ç»Ÿè®¡ =====
#     if 'level' in corrupted_df.columns:
#         print("\nğŸ“Š æŒ‰æ‰°åŠ¨çº§åˆ«(Level)çš„è¯¦ç»†ç»Ÿè®¡:")
#         level_stats = corrupted_df.groupby(['attack_type', 'level']).agg({
#             'adversarial_iou': 'mean',
#             'adversarial_dice': 'mean'
#         }).round(4)
#         print(level_stats)
        
#         # ä¿å­˜è¯¦ç»†ç»Ÿè®¡
#         level_stats_path = csv_path.replace('.csv', '_STATS_BY_LEVEL.csv')
#         level_stats.to_csv(level_stats_path, float_format='%.4f')
#         print(f"âœ… æŒ‰çº§åˆ«ç»Ÿè®¡å·²ä¿å­˜: {level_stats_path}")
    
#     return summary_df

if __name__ == "__main__":
    main()
